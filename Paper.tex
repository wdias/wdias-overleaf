\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[acronym]{glossaries}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{biblatex}

\usepackage{todonotes}
\newcommand{\db}[1]{\textcolor{blue!40}{#1}}
\newcommand{\dbc}[1]{\todo[author=Dilum, inline, color=blue!40]{#1}}


\addbibresource{mendeley.bib}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{code-style}{
  backgroundcolor=\color{backcolour}, commentstyle=\color{codegreen},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2
}
\lstset{style=code-style}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Weather Data Integration and Assimilation System\\
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Gihan Karunarathne}
\IEEEauthorblockA{\textit{Dept. Computer Science and Engineering} \\
\textit{University of Moratuwa}\\
Katubedda, Sri Lanka \\
gihan.09@cse.mrt.ac.lk}
\and
\IEEEauthorblockN{H.M.N. Dilum Bandara}
\IEEEauthorblockA{\textit{Dept. Computer Science and Engineering} \\
\textit{University of Moratuwa}\\
Katubedda, Sri Lanka \\
dilumb@cse.mrt.ac.lk}
\and
\IEEEauthorblockN{Srikantha Herath}
\IEEEauthorblockA{\textit{Center for Urban Water, Sri Lanka} \\
%\textit{Center for Urban Water, Sri Lanka}\\
Battaramulla, Sri Lanka \\
admin@curwsl.org}
}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
%We describe our experience with implementing an extendable open source Weather Data Integration and Assimilation System, which is known as \acrshort{wdias}. It uses the modern architecture pattern such as microservice in order to achieve the scalability, rather using monolithic architecture or client service architecture. It provides a modular approach to integration data from different sources and export into different formats. Also the inbuilt extension module system allow users to add new features. The open source tools that are using for \acrshort{wdias} allows to run on Cloud Computing platforms without much hassle with the auto-scaling feature allow to run \acrshort{wdias} from 1 CPU node to nodes with few hundred CPUs. The paper describes the initial design goals, evolve over few architectures to get desired performance, and explains how the system in way to achieve scalability. Later we analyse the performance test observations with the performance metrics.

\db{Numerical Weather Models (NWMs) utilize data collected via diverse sources such as automated weather stations, radars, air balloons, and satellite images. Prior to using such multimodal data into a NWM, it is necessary to transcode data into a format that can be ingested by the NWM. Moreover, the data integration system’s response time needs to be relatively low to forecast and monitor time-sensitive weather events like hurricanes, storms, and flash floods that require rapid and frequent execution of NWMs. The resulting weather data also need to be accessed by many researchers and third-party applications. Even though there are several weather data integration systems, they are based on monolithic or client-server architectures and are unable to benefit from novel computational models such as cloud computing and containers. Moreover, most of this software is proprietary or closed sourced; hence, it is difficult to customize such software for an island like Sri Lanka with different weather seasons. Therefore, in this research, we propose Weather Data Integration and Assimilation System (WDIAS) that utilizes modern architecture pattern such as microservices to achieve scalability, high availability, and low-cost operation based on cloud computing. WDIAS provides a modular architecture to integrate data from different sources, export into different formats, and the inbuilt extension module system allow users to add new features. We demonstrate the utility of WDIAS using cloud-based experimental setup and weather-related synthetic workloads.}
\end{abstract}

\begin{IEEEkeywords}
\db{Data assimilation, data integration, hierarchical databases, microservice, weather}
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
%I'm going to do this today \cite{Haggett1998AnWales}.
Give general idea on weather data integration systems.
Talk about the existing systems. And they're proprietary or close source.
(Don't dedicate another section, otherwise need to do a comparison at the performance analysis)
At the end the structure of rest of the paper

To enhance the accuracy of weather predictions, it is necessary to provide reliable and detailed weather data as inputs to \acrfull{nwm}. These NWMs utilize weather data collected via diverse sources such as automated weather stations, radars, air balloons, and satellite images. Prior to feeding such diverse data (collected from different sources that belong to different stakeholders) into respective NWMs, it is necessary to integrate data into a common format. Moreover, the data integration system’s response time needs to be relatively low to accommodate critical situations like hurricanes, storms, and floods which require rapid and frequent execution of NWMs.

Providing public access to weather data is also useful to enable many third-party applications and research. For example, logistic companies can use that data with their own model to plan and schedule their deliveries. Agricultural insurance companies can warn the farmers in advance, as well as calculate premiums based on anticipated weather patterns.

While Data Integration and Analysis System (DIAS) and Meteorological Assimilation Data Ingest System (MADIS) are some of well-known Weather Data Integration and Assimilation (WDIA) systems, they are proprietary. Further Delft-FEWS is free to use, it is not open source. Hence, users of WDIA are forced to pay heavy licenses and are unable to extend the solutions to cater to their country-specific requirements. Therefore, the objective of this research is to develop a WDIA system for Sri Lanka, as well as make it open source, so that others could use and contribute to the solution.

TODO: Specify the \acrshort{lead} service as a building block approach. \acrshort{fews} more modular approach with general adapter. And \acrshort{wdias} using microservice as module.
Similar to the \acrfull{fews} \cite{Werner2013TheSystem} 

The main purpose of this framework is to provide a platform through which opera- tional forecasting systems can be constructed, and that allows flexibility in the integration of models and data. In contrast to the NWSRFS and the RFFS systems that also follow a modular approach, the Delft-FEWS system contains no inherent hydrological model- ling capabilities within its code base. I

TODO: Update content as below, overview of rest of the paper
This paper first provides a short review of the operational forecasting process and the role of Delft-FEWS within that process. Section 3 provides an overview of the philosophy and the most important components and features of Delft-FEWS, while Section 4 discusses some example applications of the Delft-FEWS system in research and operations. A discussion of the systems strengths and limitations is provided in Section 5. Section 6 finally provides a summary of the paper, as well as an outlook on the future development of Delft-FEWS.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\db{Background}}
%\section{Modules of Weather Data System}
\cref{fi:wdia_components} shows the basic functions of a Weather data integration and assimilation system.
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{method/misc/weather_data_system_components.jpg}}
\caption{Components of a weather data system.}
\label{fi:wdia_components}
\end{figure}
\paragraph{Integration} The system should capable of integrating data from different source such as satellite data, high end and low end weather station etc. And the system should be able to handle multidimensional spatial and temporal weather data efficiently and optimally. 
\paragraph{Assimilation} Then the system should be able to fulfill weather models varying data requirements. Also those models reproduce large set of redundant data, thus system should store the bulk data while optimizing the disk space.
\paragraph{Dissemination} Then different users should be able to retrieve data as they required. Also the users should be able to easy to search into the available that in the system base on timeseries metadata or based on Geo queries.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Microservice Architecture}
Brief mentioned about soa and Actor model and why moved away from them.
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{method/microservice/k8s_architecture_v3.jpg}}
\caption{\acrfull{k8s} architecture.}
\label{fi:k8s_architecture}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\acrfull{wdias} Architecture}
%\section{Structure of \acrshort{wdias}}
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{method/microservice/microservice_architecture-handle_on_demand-v3.jpg}}
\caption{microservice architecture - handle on demand.}
\label{fi:microservice_architecture_on_demand}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{method/microservice/microservice_architecture-handle_on_async-v3.jpg}}
\caption{microservice architecture - handle asynchronously.}
\label{fi:microservice_architecture_async}
\end{figure}

\subsection{Hierarchical Database}
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.4\textwidth]{method/microservice/hierarchical_database.jpg}}
\caption{Hierarchical database.}
\label{fi:hierarchical_database}
\end{figure}

\subsection{Weather Data Preprocessing}
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.4\textwidth]{method/data_preprocess/summary_weather_data_preprocessing.jpg}}
\caption{Generic functional approach to weather data preprocessing.}
\label{fi:summary_weather_data_preprocessing}
\end{figure}

\subsection{Query Timeseries Metadata}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Performance \db{Evaluation}}
%\section{Performance Analysis}
\subsection{Test Plan and Workload}
\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{results/work_load/performance_study_v4.jpg}}
\caption{Performance study.}
\label{fi:performance_Study}
\end{figure}

\subsection{Observations}
\begin{table}[htbp]
\caption{Table type styles}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Label} & \textbf{Samples} & \textbf{Avg} & \textbf{Min} & \textbf{Max} & \textbf{Std} & \textbf{90\% Line} \\ \hline
Insert Scalar & 71727 & 34 & 13 & 1777 & 118.78 & 27 \\ \hline
Retrieve Scalar & 71693 & 7 & 5 & 1608 & 18.72 & 9 \\ \hline
Insert Grid & 7968 & 87 & 77 & 233 & 14.07 & 98 \\ \hline
Retrieve Grid & 7965 & 89 & 63 & 1694 & 37.79 & 110 \\ \hline
Query & 71704 & 1 & 0 & 203 & 2.05 & 2 \\ \hline
\textbf{TOTAL} & 310734 & 130 & 0 & 1777 & 212.35 & 501 \\ \hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Avg: Average Latency, Std: Standard Deviation.}
\end{tabular}
\label{tab:obs_all_auto_15_min_summary_latency}
\end{center}
\end{table}

\begin{table}[htbp]
\caption{Table type styles}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Label} & \textbf{Samples} & \textbf{Avg} & \textbf{Std. Dev.} & \textbf{Error \%} & \textbf{RPS} \\ \hline
Insert Scalar & 71727 & 34 & 118.78 & 0.00\% & 40.5 \\ \hline
Retrieve Vector & 71693 & 7 & 18.72 & 0.00\% & 40.5 \\ \hline
Insert Grid & 7968 & 87 & 14.07 & 0.18\% & 4.5 \\ \hline
Retrieve Grid & 7965 & 89 & 37.79 & 0.00\% & 4.5 \\ \hline
Query & 71704 & 1 & 2.05 & 0.00\% & 40.5 \\ \hline
\textbf{TOTAL} & 310734 & 130 & 212.35 & 0.00\% & 175.3 \\ \hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Avg: Average Latency.}
\end{tabular}
\label{tab:obs_all_auto_15_min_summary_throughput}
\end{center}
\end{table}

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{results/obs/all_auto/obs_all_auto_15m_res_latencies_against_hits.png}}
\caption{Performance test 15min data enabled auto-scaling - response latencies against server hits over the elapsed time.}
\label{fi:test_obs_auto_all_15_min_latency_vs_hits}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{results/obs/all_auto/obs_all_auto_15m_transaction_throughtput_vs_threads.png}}
\caption{Performance test 15min data enabled auto-scaling - transnational throughput vs number of active threads.}
\label{fi:test_obs_auto_all_15_min_throughput_vs_threads}
\end{figure}

\subsection{Discussion}
\paragraph{Latency}
The latency for each operation type kept constant over the whole test plan run time without any significant change. When the request size increased from 24 data points to 96 data points, the latency increase throughout the whole test plan with a smaller number. But for each test run the latency kept constant over the time.
During the \cref{subse:obs_test_plan_all_auto_15min} test run, the performance of the Grid data got better when compared to the \cref{subse:obs_test_plan_all_15min}. Which means by adding more resources to the \acrshort{wdias}, it can handle more workload on the system.

\paragraph{Throughput}
While keeping the latency constant without significant change, the throughput of the \acrshort{wdias} kept constant while increasing the request size from 60min data (24 data points) to 15min data (96 data points) for all the data types such as Scalar, Vector and Grid.
When number of active threads increased, the \acrshort{wdias} able to provide the same throughput with maintaining the latency stable.

One of the reason to having deviations at the peak time due to use of single instance for the data consistency such as \acrshort{influxdb} for Scalar and Vector data, and netCDF with parallel support for Grid data. Further it is possible to increase the performance of these bottlenecks much higher such as using \acrshort{influxdb} Commercial cluster support for high availability or horizontal scaling of \acrshort{influxdb}. With \acrshort{influxdb} cluster, it is possible to run multiple pods of adapter-scalar and adapter-vector for support more server hits per second.

Adapter-grid is using a Python wrapper for netCDF FORTRAN implementation with parallel IO enabled. This has some performance issues as well as memory leak issues. Since each microservice in the \acrshort{wdias} independent of technology that can use to implement the service, it will increase the performance if the adapter-grid directly ported to netCDF with a low level language such as C or FORTRAN.
Other than \acrshort{eks}, if users can use a \acrshort{k8s} cluster which support Persistent Volumes with the access of Read Write  Many \cite{LinuxFoundationPersistentKubernetes} , then it is possible to run multiple pods of adapter-grid and increase the throughput of the \acrshort{wdias}.

\paragraph{Resource Utilization}
Since \acrshort{wdias} using the \acrshort{k8s} as the container orchestration system, it allows to scale up and cool down the system as required based on the workload. This demonstrate on the test plan of \cref{subse:obs_test_plan_all_auto_15min}, and the system get scale up to the maximum at the peak time. Then cool down to single pod after finishing the test cases.
Given above \acrshort{wdias} can run from 1 CPU node to nodes with 100 CPUs. As described in the \cref{se:microservice}, it uses the many of the concept of modern microservice architecture to create stateless, failover, redundant microservice to achieve such capabilities.

\paragraph{Auto Scaling}
The \acrshort{wdias} supports auto-scaling by out of the box with \acrshort{k8s}. Services can configure with maximum number of pods in order to avoid over resource usage. When there is not much workload on the system, system cool down to less pods in order to save more resources. When there is any issue with a pod, \acrshort{k8s} auto schedule another pod and remove the unhealthy pod. Also it allows to update the system without any down time with rollback updates.

\paragraph{Risk of Unable to Process Data}
During the test performance, the \acrshort{wdias} processed many requests with higher request size than the normal usage with lower rate of failures to process the requests, mainly with insert Grid data. If the usage of \acrshort{wdias} want to reduce the risk of unable to process data, then system can configure to run with redundant pods in order to handle spike of workloads. Also while configure for the auto-scaling, the \acrshort{k8s} can configure to maintain lower amount of CPU usage such as 50\% to 60\% rather 80\%. Such configuration with always spawn new pods to handle double of current peak load.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strengths and Limitations}
\dbc{Make this the dicussion and a sub-section of Sec. 4}

\paragraph{Lack of data preprossessing modules}
The extension module enable plugin system to integrate prepossessing modules which can use for process the data which are inserted to the system or based on regular intervals. Also \acrshort{wdias} provide a more generic open interface approach to create more preprocessing modules. Since \acrshort{wdias} is an open source system, it expect more modules to be create by the community. When compared to other system like \acrshort{fews}, current system only have few extension for the testing purpose. This is one of the major area that need to be improved.

\paragraph{Supporting Irregular Grids}
At the moment \acrshort{wdias} does not support Irregular Grids, but it has the API endpoints define for the implementation which can follow the same microservice architecture. The scope of the \acrshort{wdias} does not belong such level of implementation and the scope has reduced by removing such components from the system.

\paragraph{Grid data performance}
As mentioned in the \cref{se:conclusion}, the adapter-grid is using a Python wrapper for netCDF FORTRAN implementation with parallel IO enabled. This has some performance issues as well as memory leak issues. Since each microservice in the \acrshort{wdias} independent of technology that can use to implement the service, it will increase the performance if the adapter-grid directly ported to netCDF with a low level language such as C or FORTRAN. They are some future work that can focus on improving the performance of grid data.

\paragraph{Define infrastructure as code}
Physical nodes for the \acrshort{k8s} cluster created using Cloud Computing provider such as \acrshort{eks}. And defining the each pod resource limitations at the helm chart level. But the infrastructure that need to deploy the \acrshort{wdias} can define as code such as using tools like Teraform which is independent of the Cloud Computing provider. Using such tool, users will able to easy deploy the \acrshort{wdias} on any Cloud provider without much hassle.

\paragraph{Further improve hierarchical database performance}
As further described in \cref{se:conclusion}, it is possible to increase the performance of these bottlenecks much higher such as using \acrshort{influxdb} Commercial cluster support for high availability or horizontal scaling of \acrshort{influxdb}. With \acrshort{influxdb} cluster, it is possible to run multiple pods of adapter-scalar and adapter-vector for support more server hits per second.
Other than that, the \acrshort{wdias} performance can improve via partitioning the timeseries key space into multiple \acrshort{influxdb} instances. The adapter-scalar or adapter-vector can improve to plug multiple instance of \acrshort{influxdb} instances by changing the configurations. As an example, based on the key attribute \cref{subse:timeseries_key_attributes} Timeseries Type, the adapter-scalar can connect to four instance of \acrshort{influxdb} instances such as  External Historical, External Forecast, Simulated Historical, and Simulated Forecast etc.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
\dbc{Summary is too long. Should not be more than a single para}
To enhance the accuracy of the weather prediction, it is required to have reliable weather data for \acrshort{nwm}. Most of existing weather data systems are proprietary or close sourced, or not up to date with the existing cloud computing technologies.
We proposed an extendable open source Weather Data Integration and Assimilation Systems which is known as \acrshort{wdias}. It focused on providing efficiently integrates weather data from different sources with quality control and supporting steaming large size of data. And compatible with current cloud computing technologies and architecture patterns.

First the architecture starts with SOA using a \acrfull{esb}, and then moved to Actor model based architecture. After comparing the disadvantages of using such architecture with the system requirements, final architecture come up with modern microservice architecture.
Based on the microservice architecture patterns and the nature of the weather metadata, the \acrshort{wdias} came up with the idea of hierarchical database structure in order to provide higher performance while store the weather data. The system uses \acrshort{influxdb} timeseries database for storing Scalar and Vector timeseries data, and using \acrshort{netCDF} for storing Grid timeseries data.
Also the system provide a generic open mechanism to integrate new modules as extension in order to enhance the features of the system. This capability enable to integrate weather data preprocessing flows as extension modules.
The extension API provide easy access to create and modify the extension triggers on the fly without stopping the system or any downtime in order to change the configurations.
The system provides extensive timeseries query endpoints to easy search over the system timeseries metadata with supporting Geo based queries.

\acrshort{wdias} performance test is perform using the \acrshort{jmeter} tool's distributed testing capabilities which separately testing each modules. Then the test plans are performed with increasing the request size, and monitored the performance metrics. The system is setup on the \acrfull{eks} as per the configurations of \cref{subse:test_sys_config}.
During the performance test plans, the system were able to provide constant throughput by keeping the latency constant while increasing the workload. Which exhibit the scalability of the system.
With the \acrshort{k8s} auto-scaling, the \acrshort{wdias} were able to elastically adjust the number of pods according to the workload with the given configurations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgment}
\db{This research is supported in part by the grant from the Center for Urban Water, Sri Lanka.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\graphicspath{ {./images/} }
\input{glossary.tex}
% \bibliographystyle{plain}
% \addbibresource{mendeley.bib}
\printbibliography[title={References}]

\end{document}
