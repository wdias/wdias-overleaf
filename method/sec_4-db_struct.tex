\section{Hierarchical Database}
\label{se:db_struct}

The database structure of WDIAS mainly depends on the key attributes of the timeseries. \hl{A brief summary of possible value for timeseries can be describe as below};
\dbc{Clerly mention why a hierarchical design is needed.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Key Attributes of Timeseries}
\label{subse:timeseries_key_attributes}
\paragraph{Module ID}-- String field which describe the source of the data generated. e.g., hec-hms, flow2d, weather-station etc

\paragraph{Value Type}-- Scalar, Vector, Grid are the Value Types which are interested in the \acrshort{wdias}.

\paragraph{Location}-- Location of the timeseries. All locations have unique String identifier called locationId. Further, there are two type of location types that is interested in the WDIAS, namely:
\begin{itemize}
  \item \emph{Point locations}-- Contains a name which is human readable. lat and lon of the location on earth surface.
  \begin{lstlisting}[language=Python]
    {
        "locationId": "wdias-hanwella",
        "name": "Hanwella",
        "lat": 6.909722222,
        "lon": 80.08166667
    }
  \end{lstlisting}
  \dbc{Remove additional line.}
  
  \item \emph{Regular Grid locations} -- Contains a name which is human readable. The grid presents by dividing into equal size cells. Thus, it need the number of rows and columns. 
  And the location of the first cell and the width and height of it.
  \begin{lstlisting}[language=Python]
      {
        "locationId": "wdias_kelani_basin",
        "description": "Kelani Basin",
        "rows": 120,
        "columns": 139,
        "geoDatum": "Kandawala",
        "gridFirstCell": {
            "firstCellCenter": {
                "x": 397074.0,
                "y": 504875.0
            },
            "xCellSize": 250.0,
            "yCellSize": 250.0
        }
    }
  \end{lstlisting}
  \item \emph{Irregular Grid locations} -- (endpoints are available with in the WDIAS system, but skipped since it is out of the interest of the scope.)
\end{itemize}

\paragraph{Parameter}
Parameter describe the variable measuring against a location. All parameters ahve a unique String identifier called as \textit{parameterId}. A parameter can be use in multiple locations.
While defining a parameter, there are three required fields which need to be provided such as variable, unit and \textit{parametertype}.
\begin{itemize}  
  \item \emph{Variable} -- Nature of the variable measuring. Example Precipitation, Temperature and WaterLevel etc
  \item \emph{Unit} -- metric unit of measuring
  \item \emph{Parameter Type} -- Should be one of Instantaneous, Accumulative, or Mean
  \begin{lstlisting}[language=Python]
    {
      "parameterId": "O.Precipitation",
      "variable": "Precipitation",
      "unit": "mm",
      "parameterType": "Instantaneous"
    }
  \end{lstlisting}
\end{itemize}

\subsubsection{Timeseries Type}
Timeseries Type can be combination of Source followed by category:
\begin{itemize}
  \item Sources - External or simulated
  \item Category - Historical or forecast
\end{itemize}
\dbc{Explain each with sufficient detail.}

\paragraph{Time Step}-- All Time Steps has an uniqie String identifier called as timeStepId. Unit should be one of Second, Minute, Hour, Day, Week, Month, Year, or NonEquidistant. One of multiplier or divider can be use to define the interval between each measurement.
\begin{lstlisting}[language=Python]
{
    "timeStepId": "each_min",
    "unit": "Minute",
    "multiplier": 1,
    "divider": 0
}
\end{lstlisting}

Among above key attributes; Location, Parameter and Time Step attributes are composite attributes. But each of them have an unique identifier.
Given that, a timeseries can uniquely indentify by moduleId, valueType, parameterId, locationId, timeseriesType and timeStepId.
\begin{lstlisting}[language=Python]
{
	"moduleId": "HEC-HMS",
	"valueType": "Scalar",
	"parameterId": "O.Precipitation",
	"locationId": "wdias_hanwella",
	"timeseriesType": "External_Historical",
	"timeStepId": "each_hour",
}
\end{lstlisting}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/microservice/hierarchical_database.jpg}
    \caption{Hierarchical database}
    \label{fi:hierarchical_database}
\end{figure}

\dbc{Fig. 3.6 needs a more meaningful title.}

WDIAS is using a hierarchical database, with following the concept of Database per Service which is described in the \emph{Database per Service} in \cref{subse:database_per_service}.
Following chapters described the usage of databases in WDIAS and reason behind the selection.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\acrshort{rdbms}}
\label{subse:mysql}
\dbc{Needs a more meaningful Sec. title}

%There are lots of \acrshort{rdbms} available and for 
\acrshort{wdias} is using SQL as the \acrfull{rdbms}. 
%SQL database has fewer version of open source and it is also possible to gain better performance with commercial versions. 
Since WDIAS scope is to using open source tools, it is using \acrshort{mysql} as persistent database for storing timeseries metadata described above.
One instance of \acrshort{mysql} is using only by adapter-metadata service.
Other than that, another instance of \acrshort{mysql} is using for adapter-extension which will be describe in more detail \cref{se:data_preprocess}.
\acrshort{mysql} is used only for these services, those will only keep the consistency of the schema for timeseries metadata and extension metadata.
As mentioned in \cref{subse:redis}, it uses \acrshort{redis} instance is using for caching the data from \acrshort{mysql}, since the \acrshort{mysql} database instances, itself not going to get much load.
Other than MySQL, there are many open source databases can be used to replace the same functionality.
\dbc{First start with a brief discussion on why a RDBMS is needed}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Timeseries Database}
\label{subse:influxdb}
Among several timeseries open source databases, \acrshort{influxdb} \cite{influxdbInfluxDBDocumentation} \hl{has higher number of usage and support. Database is written in Golang programming language, and} has higher performance, and has following supports;
\begin{itemize}
  \item Open timeseries DB with MIT license
  \item Support SQL-Like query language
  \item Clustering available with a commercial version
\end{itemize}
Other than \acrshort{influxdb}, another database is Elastic Search which is mainly using for indexing for searching.
With changing the configurations of the \acrshort{influxdb}, it is possible to adapt as required. As mention in \cite{influxdbInfluxDBDocumentation}, 
\acrshort{influxdb} can setup on a computer which will give the required performance. Going further, users can use commercial version of \acrshort{influxdb} in order to gain more performance.

Two instance of \acrshort{influxdb} is using in the WDIAS system by adapter-scalar and adapter-vector services. For the scalability, the system uses \emph{Database per Service} as mentioned in \cref{subse:database_per_service}.
But further, it split into two services, referring to the \cref{subse:scale_cube}, the Z-axis scaling, the data is partitioned among few servers based on valueType key attribute of timeseries.
Which also conclude the concept of splitting into more services based on other key attributes such as timeseriesType, if further performance required.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\acrfull{netCDF}} 
\label{subse:netcdf}
\acrshort{netCDF} \cite{unidataUnidataNetCDF} is a self-describing, machine-independent data formats that support creation, access, and sharing of array-oriented scientific data.
And it also has the support for parallel file access.
NetCDF is widely using in sciencetific domain due to it's capability of storing data in multi dementions easily and flexibility with storing many of the sciencetific data. \hl{
Python wrapper for NetCDF-C library using in the WDIAS system, and use by adapter-grid service.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Document-oriented Database}
\label{subse:mongodb}

\acrshort{wdias} is using \acrshort{mongodb} as the document-oriented databse, as it has the Geo searching capabilities.
\acrshort{mongodb} \cite{mongodbMongoDBManual} is a general purpose, document-based, distributed database. And it supports:
\dbc{Need for a mix of relational, time series, document stores, and in-memory need to be first mentioned and justified in high-level design of EDIAS above.}
\begin{itemize}
  \item Supports query operations on geo-spatial data \cite{mongodbMongoDBManual}
  \item Clustering and Sharding available for scalability and reliability
\end{itemize}
\acrshort{mongodb} geo-spatial features are using for support Geo queries in the WDIAS. Other than that, external timeseries metadata queries are served by the indexed timeseries metadata data.
If metadata not present in the adapter-query, if fetch data from the adapter-metadata, then indexed and cache in the \acrshort{mongodb}. Vise a versa, if new timeseries create in the adapter-metadata, it trigger an event to adapter-query to index the new timeseries.
In \cref{subse:scale_cube}, the Y-axis scaling concept is using here by splitting into the multiple services based on the functionality and scale the system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{In-Memory Database}
\label{subse:redis}
\acrshort{wdias} is using \acrshort{redis} \cite{redisRedisDocumentation} as the In-Memory database, since it's widely using tool with good support, and it support few other features such as Publisher Subscriber capabilities.
\acrshort{redis} is an open source (BSD licensed), used as a database, cache. Clustering is available for scalability.
\acrshort{redis} uses as in-memory caching for fast access of repreative access data in adapter-metadata and adapter-extension.
Other than that, adapter-status uses \acrshort{redis} as key value pair store for getting the status for async handling requests such as storing Grid data.
In adapter-extension uses Redis's Publisher Subscriber capabilities in order to create a cron job in extension-scheduler when new extension create on \cref{se:data_preprocess}
