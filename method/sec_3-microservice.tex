\section{Microservice Architecture}

The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies \cite{LewisMicroservices}.

Among the characteristics of \acrfull{microservice}, few characteristics heavily affect while moving from \acrshort{soa} to \acrshort{microservice}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Smart Endpoints And Dumb Pipes}
\label{subse:dumb_pipes}
When building communication endpoints, many architecture approach with putting significant smart into the communication mechanism. One good example is \acrshort{esb} what we discussed in section \ref{se:architectural_decisions}. But microservice follows alternative approach: \emph{Smart endpoints and dumb pipes} \cite{LewisMicroservicesPipes}.
Applications built from microservices aim to be as decoupled and as cohesive as possible. They own their own domain logic and act more as filters in the classical Unix sense. After receiving a request, applying logic as appropriate and producing a response. And it uses simple RESTish protocols rather than complex protocols.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pattern: Database per Service}
\label{subse:database_per_service}
- Pattern: Database per service 

\acrshort{microservice} prefer letting each service manages its own database, either different instances of the same database technology, or entirely different database systems - an approach called \emph{Polyglot Persistence} \cite{LewisMicroservicesManagement}.

Keep each microservice’s persistent data private to that service and accessible only via its API. 
There are a few different ways to keep a service’s persistent data private. You do not need to provision a database server for each service. For example, if you are using a relational database then the options are \cite{RichardsonMicroservicesService}:
\begin{itemize}
    \item \emph{Private-tables-per-service} – each service owns a set of tables that must only be accessed by that service
    \item \emph{Schema-per-service} – each service has a database schema that’s private to that service
    \item \emph{Database-server-per-service} – each service has its own database server.
\end{itemize}
Private-tables-per-service and schema-per-service have the lowest overhead. Using a schema per service is appealing since it makes ownership clearer. Some high throughput services might need their own database server.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pattern: Sagas}
\label{subse:sagas}
In order to ensure loose coupling, each service has its own database. Maintaining data consistency between services is a challenge because 2 phase-commit/distributed transactions is not an option for many applications. An application must instead use the Saga pattern. A service publishes an event when its data changes. Other services consume that event and update their data \cite{RichardsonMicroservicesSagas}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Scale Cube}
\label{subse:scale_cube}
The scalability of a system can explain via a concept called \emph{Scale Cube} which talk about the scalability of the application throw X, Y and Z axis.

\subsubsection{X-axis Saling}
X-axis scaling consists of running multiple copies of an application behind a load balancer. If there are N copies then each copy handles 1/N of the load. This is a simple, commonly used approach of scaling an application TODO.

\subsubsection{Y-axis Scaling}
Unlike X-axis and Z-axis, which consist of running multiple, identical copies of the application, Y-axis axis scaling splits the application into multiple, different services. Each service is responsible for one or more closely related functions. There are a couple of different ways of decomposing the application into services.
\begin{itemize}
    \item verb-based decomposition ex: checkout.
    \item decompose the application by noun ex: customer management. 
    \item An application might use a combination of verb-based and noun-based decomposition.
\end{itemize}
    
The microservice architecture is an application of Y-axis scaling.

\subsubsection{Z-axis Scaling}
When using Z-axis scaling each server runs an identical copy of the code (similar to X-axis scaling). The big difference is that each server is responsible for only a subset of the data. 
Z-axis splits are commonly used to scale databases. Data is partitioned (a.k.a. sharded) across a set of servers based on an attribute of each record.

Even \acrshort{wdias} is design based on the Y-axis scaling, it's possible to use the Z-axis scaling to scalability of the system further. This will be more discuss in the section \ref{se:discussion}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Brief introduction to the \acrfull{k8s}}
\label{sebse:k8s_intro}

\acrfull{k8s} is an open-source system for automating deployment, scaling, and management of containerized applications \cite{LinuxFoundationProduction-GradeKubernetes}. It groups containers that make up an application into logical units for easy management and discovery.
\begin{figure}[htp]
    \centering
    \includegraphics[width=1\textwidth]{method/microservice/k8s_architecture_v3.jpg}
    \caption{\acrfull{k8s} architecture.}
    \label{fi:k8s_architecture}
\end{figure}
Components of \acrshort{k8s},
\begin{itemize}
    \item Pods – Cluster of containers that can group other container images in a single unit.
    \item Nodes - the machines (VMs, physical servers, etc) in a cluster that run your applications and cloud workflows.
    \item kubelet - An agent that runs on each node in the cluster. It makes sure that containers are running in a pod.
    \item kube-proxy - A network proxy that runs on each node in the cluster, and maintains network rules on nodes.
    \item Kubernetes master - Responsible for maintaining the desired state for your cluster.
    \item etcd - Consistent and highly-available key value store used as Kubernetes’ backing store for all cluster data.
\end{itemize}
Users can add much as required Nodes into the \acrshort{k8s} cluster, and \acrshort{k8s} manage and deploy application as pods into cluster nodes.
Each microservice can deploy as a Pod which is a group of containerize applications. And \acrshort{k8s} able to scale as much as user want as described above.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\acrshort{wdias} Microservices}
\label{sebse:wdias_microservices}
In the figures of \ref{fi:wdias_micro_on_demand} and \ref{fi:wdias_micro_async} each circle represent a microservice, and those are implemented as containerized applications.
\begin{figure}[htp]
    \centering
    \includegraphics[width=1\textwidth]{method/microservice/microservice_architecture-handle_on_demand-v3.jpg}
    \caption{\acrshort{wdias} architecture for server requests on demand}
    \label{fi:wdias_micro_on_demand}
\end{figure}
In left side of the figure \ref{fi:wdias_micro_on_demand} shows the import modules of the \acrshort{wdias}, and right side show the export modules. As it explained section \ref{subse:dumb_pipes}, each import microservice only do specific task of converting and forwarding the request to the correct data adapter module.
For each data type, there is a adapter microservice is running which is optimized to storing such type of data. And the metadata data of the timeseries store using \acrshort{rdbms} which gives more performance over retrieving metadata data. The metadata is cached with In-Memory database in order to fast access as mentioned in section \ref{subse:redis}.
The system generate a unique identifier for each timeseries, and throw out the \acrshort{wdias}, other microservice use it to handle data for fast access.

\begin{figure}[htp]
    \centering
    \includegraphics[width=1\textwidth]{method/microservice/microservice_architecture-handle_on_async-v3.jpg}
    \caption{\acrshort{wdias} architecture for handle request asynchronously}
    \label{fi:wdias_micro_async}
\end{figure}
Export module microservice follows the same concepts and provide the capability to export the data into required formats of the weather models.
Each adapter follows the concept of database per service as mentioned in the section \ref{subse:database_per_service}. This gives the freedom for \acrshort{wdias} to scale better with \acrshort{k8s}.
As shown in the figure \ref{fi:wdias_micro_on_demand}, when a smaller size request come to the system, it handle on demand and response back. But as shown in figure \ref{fi:wdias_micro_async}, when a request with larger size come to the system, it store the data for asynchronously process the data and response with a unique id which can use to verify whether data processed successfully or not.

\begin{figure}[htp]
    \centering
    \includegraphics[width=1\textwidth]{method/microservice/separation_microservices-v3.jpg}
    \caption{Separation \acrshort{wdias} microservices}
    \label{fi:wdias_micro_separation}
\end{figure}
The figure \ref{fi:wdias_micro_on_demand} show the clear separation of microservices into the modules of the \acrshort{wdias}. As it shown, each adapter has isolated database, and database is hosted separately for the high performance.
Apart from that, as we further discuss in section \ref{se:data_preprocess}, the extension modules are running separately such as Interpolation, Transformation and Validation etc.
The Extension Adapter allow users to register new triggers for the extensions. And extension scheduler triggers the events based on time and extension handler triggers event based on data change.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\acrshort{wdias} API Convention}
\label{sebse:wdias_api}
One of the main design consideration in \acrshort{wdias} is the convention of defining the APIs. It follows the simple RESTful API, and allow users to interact with HTTP methods.

\emph{Timeseries} endpoints allow to interact with Metadata Adapter, and those are cache on the Query Handler in order to perform search queries.
\begin{itemize}
    \item parameter
    \begin{itemize}
        \item \emph{/parameter}
    \end{itemize}
    \item timeStep
    \begin{itemize}
        \item \emph{/timestep}
    \end{itemize}
    \item location
    \begin{itemize}
        \item \emph{/location/point}
        \item \emph{/location/regularGrid}
    \end{itemize}
    \item timeseries
\end{itemize}

\emph{Import} endpoints allow to upload data into the \acrshort{wdias} system.
\begin{itemize}
    \item \emph{/import/json/raw}
    \item \emph{/import/ascii-grid/upload}
\end{itemize}

\emph{Export} endpoints allow to get/download data from the \acrshort{wdias} system.
\begin{itemize}
    \item \emph{/export/json/raw}
    \item \emph{/export/ascii-grid/binary}
\end{itemize}

\emph{Extensions} endpoints for configure extensions.

These details describes in the section \ref{se:data_preprocess}.

The API convention of \texttt{/MODULE/DATA\_FORMAT/DATA\_OPERATION\_TYPE} allows users to integrate new import or export modules into the system as well as add new data types.
