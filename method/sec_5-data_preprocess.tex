\section{Data Prepossessing}
\label{se:data_preprocess}

The data imported via import modules may have incorrect data, missing data and not compatible with direct feed into simulation modules. 
Thus it required to preprocess the data before use it. The WDIAS supports these capabilities via the \emph{extension} modules. The current system has a few inbuilt extensions such as Interpolation, Transformation, and Validation. Other than those, it possible to add more extensions as required.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.5\textwidth]{method/data_preprocess/weather_data_preprocessing.jpg}
    \caption{\hl{Generic mathematical function model for weather data preprocessing}}
    \label{fi:weather_data_preprocessing}
\end{figure}

The WDIAS provides the support via a simple generic mathematical function model. Each extension is considering as a mathematical function which can take \texttt{p} number of input timeseries variables and output \texttt{n} number of timeseries variables. Other than that, at the time of processing the system can configure to provide bind constant which can provide while configuring an extension. This means it is possible to change the behavior of an existing function by providing different bind constant at the time of creating new triggers for an extension.

\subsection{Interpolation}
The Interpolation module generates data at desired locations or desired points in time using either a serial or spatial interpolation technique. It is applied for the filling in of data gaps in measured on-line data, as well as to derive spatially distributed data for meteorological time series, such as precipitation and temperature, based on information available at neighboring locations.

\paragraph{Serial Interpolation}-- In serial interpolation mode, interpolation is done to fill any gaps in a time series. The interpolation module will only consider the time series itself in filling these gaps.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/data_preprocess/serial_interpolation.jpg}
    \caption{Serial interpolation.}
    \label{fi:serial_interpolation}
\end{figure}

\paragraph{Spatial Interpolation}-- In spatial interpolation mode, the interpolation can be either applied to fill gaps in time series, or to create a new time series for a location using data from other (spatially distributed) locations. Spatial interpolation can also be applied for sampling scalar time series from grid time series, for re-sampling grids, or for creating grids from timeseries data.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/data_preprocess/spatial_interpolation.jpg}
    \caption{Spatial interpolation.}
    \label{fi:spatial_interpolation}
\end{figure}

\subsection{Transformation}- Simple arithmetic manipulation, Time interval transformation and Shifting the series in time Specific hydro-meteorological transformation such as stage discharge relationships.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/data_preprocess/transformation.jpg}
    \caption{\hl{Time interval transformation.}}
    \label{fi:transformation}
\end{figure}

\subsection{Validation}- Checks for counting reliable, doubtful, unreliable, and missing values
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/data_preprocess/validation.jpg}
    \caption{\hl{Timeseries data validation against a set of rules.}}
    \label{fi:validation}
\end{figure}

\subsection{\hl{Data Preprocessing API}}
In the WDIAS, it is possible to create new trigger for an extension via POST request to /extension endpoint.
\begin{lstlisting}[language=Python]
{
    "extensionId": "",
    "extension": "Interpolation/Transformation/Validation",
    "function": "",
    "variables": [
        {
            "variableId": "",
            "metadata/metadtaIds": {
            }
        }
    ],
    "inputVariables": [],
    "outputVariables": [],
    "trigger": [
        {
            "trigger_type": "OnChange/OnTime",
            "trigger_on": []
        }
    ],
    "options": {
    }
}
\end{lstlisting}
\begin{itemize}
    \item extensionId -- An unique identifier for new extension trigger. Should be unique among all extensions.
    \item extension -- The main extension category which is responsible for handling the extension with extracting data required and storing the output. Interpolation/Transformation/Validation support for the moment.
    \item function -- Name of the microservice which is handling the input to output mapping. Fn() function in the \cref{fi:weather_data_preprocessing}.
    \item variables -- Array timeseries mapping to variables. Multiple variables can be define with metadata or metadataIds of timeseries. Can be use same variable on inputVariables and outputVariables below.
    \item inputVariables -- Timeseries that need to be provide into the function
    \item outputVariables -- Timeseries that output from the function
    \item trigger -- Type of trigger for the extension. Should be one of OnTime or OnChange.
    \begin{itemize}
        \item trigger -- OnChange
        \item trigger\_on -- List of timeseries to listen on change and trigger the extension
    \end{itemize}
    \begin{itemize}
        \item trigger -- OnTime
        \item trigger\_on -- List of schedules that need to be trigger the extension in cronjob string format
    \end{itemize}
    \item options -- Bind Constant which is bind at the time of creating new extension trigger and pass on triggering the extension.
\end{itemize}

\subsubsection{Extension Handler}
Extension Handler is responsible for triggering the correct Extension with metadata when there is any change on the subscribed extension trigger's \emph{OnChange} timeseries.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.6\textwidth]{method/data_preprocess/validation.jpg}
    \caption{Extension handler.}
    \label{fi:extension_handler}
\end{figure}

\hl{As an example,} when new data imported into one of the adapter-scalar or adapter-vector, those notify the extension-handler. Then extension handler checks whether there is any extension subscribed for particular timeseries, and triggers it via triggering an event on particular extensions.

To improve the performance of matching triggers against a timeseries, the WDIAS added two mechanisms. For the separation of service responsibilities, those functionalities reside in the adapter-extension and expose via an endpoint. First, other than storing extension metadata in MySQL instance of adapter-extension, it also stores the data in reverse lookup table called triggers. Using this reverse lookup table, for a given trigger\_type and timeseries, it can retrieve the extensions which are part of given timeseries. Thus, the response which is received by the 
extension-handler only contains the extensions to be triggered. No additional filtering needs to be done at the extension-handler service.
Second, cache the resulting trigger\_type and timeseries data in the \acrshort{redis} database for fast access and avoid too many queries on the \acrshort{mysql} database.

\paragraph{Extension Scheduler}-- Extension Handler is responsible for triggering the correct Extension with metadata at a given time which is provided at the creation on extension trigger with the value of OnTime cronjob string value. To improve the performance of triggering cronjobs at given time schedules, the WDIAS added few optimization mechanisms.
Same as for extension-handler, the adapter-extension exposes an endpoint to retrieve extension metadata grouped by cronjob time. Then use \acrshort{go} to implement the extension-handler to fast processing the extensions. After retrieve extensions which is grouped by cronjob time; within the extension-handler, it schedules programmatic cronjobs to trigger at given times. When each cronjob triggers at the given time, it also contains the extensions to be triggered. Fetching extension data and creating cronjobs occur with a long period to avoid heavy overhead.
When a new extension trigger created, those data push into a \acrshort{redis} list. Then pulling from the extension-handler in regular time intervals and create new cronjobs for mentioned cronjob time.
As mentioned above, to avoid the expansion of the programmatic cronjob list which are created for new extension triggers, all cronjobs fetch again in a long period and flush the previously scheduled cronjobs.
The extension-handler should be run as a single entity for the atrocity, to avoid triggering the same extension twice.